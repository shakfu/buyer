version: '3.8'

# Production MinIO Configuration
# This setup includes:
# - Distributed MinIO (4 nodes for high availability)
# - TLS/SSL support
# - Health checks
# - Resource limits
# - Logging configuration
# - Backup configuration

services:
  # MinIO Node 1
  minio1:
    image: quay.io/minio/minio:latest
    hostname: minio1
    ports:
      - "9000:9000"   # API
      - "9001:9001"   # Console (only on node 1)
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_REGION: ${MINIO_REGION:-us-east-1}
      MINIO_BROWSER: "on"
      MINIO_PROMETHEUS_AUTH_TYPE: "public"
      # Distributed setup
      MINIO_DISTRIBUTED_MODE_ENABLED: "yes"
      MINIO_DISTRIBUTED_NODES: "http://minio{1...4}:9000/data"
    volumes:
      - minio1_data:/data
      - ./certs:/root/.minio/certs  # TLS certificates
    command: server http://minio{1...4}:9000/data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "https://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    networks:
      - buyer-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # MinIO Node 2
  minio2:
    image: quay.io/minio/minio:latest
    hostname: minio2
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_REGION: ${MINIO_REGION:-us-east-1}
      MINIO_DISTRIBUTED_MODE_ENABLED: "yes"
      MINIO_DISTRIBUTED_NODES: "http://minio{1...4}:9000/data"
    volumes:
      - minio2_data:/data
      - ./certs:/root/.minio/certs
    command: server http://minio{1...4}:9000/data
    healthcheck:
      test: ["CMD", "curl", "-f", "https://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    networks:
      - buyer-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # MinIO Node 3
  minio3:
    image: quay.io/minio/minio:latest
    hostname: minio3
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_REGION: ${MINIO_REGION:-us-east-1}
      MINIO_DISTRIBUTED_MODE_ENABLED: "yes"
      MINIO_DISTRIBUTED_NODES: "http://minio{1...4}:9000/data"
    volumes:
      - minio3_data:/data
      - ./certs:/root/.minio/certs
    command: server http://minio{1...4}:9000/data
    healthcheck:
      test: ["CMD", "curl", "-f", "https://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    networks:
      - buyer-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # MinIO Node 4
  minio4:
    image: quay.io/minio/minio:latest
    hostname: minio4
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_REGION: ${MINIO_REGION:-us-east-1}
      MINIO_DISTRIBUTED_MODE_ENABLED: "yes"
      MINIO_DISTRIBUTED_NODES: "http://minio{1...4}:9000/data"
    volumes:
      - minio4_data:/data
      - ./certs:/root/.minio/certs
    command: server http://minio{1...4}:9000/data
    healthcheck:
      test: ["CMD", "curl", "-f", "https://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    networks:
      - buyer-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Load Balancer (NGINX)
  nginx:
    image: nginx:alpine
    ports:
      - "443:443"
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./certs:/etc/nginx/certs:ro
    depends_on:
      - minio1
      - minio2
      - minio3
      - minio4
    networks:
      - buyer-network
    restart: unless-stopped

  # Prometheus (optional - for monitoring)
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - buyer-network
    restart: unless-stopped

volumes:
  minio1_data:
    driver: local
  minio2_data:
    driver: local
  minio3_data:
    driver: local
  minio4_data:
    driver: local
  prometheus_data:
    driver: local

networks:
  buyer-network:
    driver: bridge

# Usage:
#
# 1. Generate TLS certificates:
#    mkdir -p certs
#    openssl req -new -x509 -days 365 -nodes \
#      -out certs/public.crt \
#      -keyout certs/private.key \
#      -subj "/C=US/ST=State/L=City/O=Organization/CN=minio.yourdomain.com"
#
# 2. Create .env file:
#    MINIO_ROOT_USER=your-secure-access-key
#    MINIO_ROOT_PASSWORD=your-secure-secret-key-min-32-chars
#    MINIO_REGION=us-east-1
#
# 3. Create NGINX config:
#    mkdir -p nginx
#    # See nginx.conf.example
#
# 4. Create Prometheus config (optional):
#    mkdir -p prometheus
#    # See prometheus.yml.example
#
# 5. Start cluster:
#    docker-compose -f docker-compose.minio.prod.yml up -d
#
# 6. Check cluster status:
#    docker-compose -f docker-compose.minio.prod.yml ps
#    docker-compose -f docker-compose.minio.prod.yml logs -f minio1
#
# 7. Access MinIO Console:
#    https://your-domain.com:9001
#
# Notes:
# - This is a 4-node distributed setup with erasure coding
# - Requires at least 4 drives across 4 nodes for redundancy
# - Each node can handle node failures (up to 2 with 4 nodes)
# - For production, use external load balancer (AWS ALB, GCP Load Balancer, etc.)
