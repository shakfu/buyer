version: '3.8'

# Production Docker Compose Configuration
# This setup includes:
# - PostgreSQL database with replication support
# - Distributed MinIO (4 nodes for high availability)
# - Buyer application with multiple replicas
# - NGINX load balancer
# - Resource limits and health checks
# - Production security settings

services:
  # PostgreSQL Primary Database
  postgres:
    image: postgres:16-alpine
    container_name: buyer-postgres-prod
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
      PGDATA: /var/lib/postgresql/data/pgdata
      # Enable replication
      POSTGRES_REPLICATION_MODE: master
      POSTGRES_REPLICATION_USER: ${POSTGRES_REPLICATION_USER:-replicator}
      POSTGRES_REPLICATION_PASSWORD: ${POSTGRES_REPLICATION_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./postgres/pg_hba.conf:/etc/postgresql/pg_hba.conf:ro
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - buyer-network
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 4G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"

  # MinIO Node 1
  minio1:
    image: quay.io/minio/minio:latest
    hostname: minio1
    restart: unless-stopped
    ports:
      - "9000:9000"   # API
      - "9001:9001"   # Console (only on node 1)
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_REGION: ${MINIO_REGION:-us-east-1}
      MINIO_BROWSER: "on"
      MINIO_PROMETHEUS_AUTH_TYPE: "public"
      MINIO_DISTRIBUTED_MODE_ENABLED: "yes"
      MINIO_DISTRIBUTED_NODES: "http://minio{1...4}:9000/data"
    volumes:
      - minio1_data:/data
      - ./certs:/root/.minio/certs
    command: server http://minio{1...4}:9000/data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
    networks:
      - buyer-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # MinIO Node 2
  minio2:
    image: quay.io/minio/minio:latest
    hostname: minio2
    restart: unless-stopped
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_REGION: ${MINIO_REGION:-us-east-1}
      MINIO_DISTRIBUTED_MODE_ENABLED: "yes"
      MINIO_DISTRIBUTED_NODES: "http://minio{1...4}:9000/data"
    volumes:
      - minio2_data:/data
      - ./certs:/root/.minio/certs
    command: server http://minio{1...4}:9000/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
    networks:
      - buyer-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # MinIO Node 3
  minio3:
    image: quay.io/minio/minio:latest
    hostname: minio3
    restart: unless-stopped
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_REGION: ${MINIO_REGION:-us-east-1}
      MINIO_DISTRIBUTED_MODE_ENABLED: "yes"
      MINIO_DISTRIBUTED_NODES: "http://minio{1...4}:9000/data"
    volumes:
      - minio3_data:/data
      - ./certs:/root/.minio/certs
    command: server http://minio{1...4}:9000/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
    networks:
      - buyer-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # MinIO Node 4
  minio4:
    image: quay.io/minio/minio:latest
    hostname: minio4
    restart: unless-stopped
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
      MINIO_REGION: ${MINIO_REGION:-us-east-1}
      MINIO_DISTRIBUTED_MODE_ENABLED: "yes"
      MINIO_DISTRIBUTED_NODES: "http://minio{1...4}:9000/data"
    volumes:
      - minio4_data:/data
      - ./certs:/root/.minio/certs
    command: server http://minio{1...4}:9000/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
    networks:
      - buyer-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # MinIO Client for setup automation
  mc:
    image: minio/mc:latest
    container_name: buyer-mc-prod
    depends_on:
      minio1:
        condition: service_healthy
      minio2:
        condition: service_healthy
      minio3:
        condition: service_healthy
      minio4:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      echo 'Waiting for MinIO cluster to be ready...';
      sleep 10;
      /usr/bin/mc alias set buyerprod http://minio1:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD};
      /usr/bin/mc mb --ignore-existing buyerprod/vendor-docs;
      /usr/bin/mc mb --ignore-existing buyerprod/product-docs;
      /usr/bin/mc mb --ignore-existing buyerprod/quote-docs;
      /usr/bin/mc mb --ignore-existing buyerprod/po-docs;
      /usr/bin/mc mb --ignore-existing buyerprod/requisition-docs;
      /usr/bin/mc mb --ignore-existing buyerprod/project-docs;
      /usr/bin/mc mb --ignore-existing buyerprod/brand-docs;
      /usr/bin/mc version enable buyerprod/vendor-docs;
      /usr/bin/mc version enable buyerprod/quote-docs;
      /usr/bin/mc version enable buyerprod/po-docs;
      /usr/bin/mc ilm import buyerprod/vendor-docs < /config/ilm.json || true;
      echo 'MinIO cluster setup completed!';
      echo 'Buckets created:';
      /usr/bin/mc ls buyerprod;
      echo 'Cluster status:';
      /usr/bin/mc admin info buyerprod;
      exit 0;
      "
    networks:
      - buyer-network

  # Buyer Application (multiple replicas for HA)
  buyer:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        VERSION: ${VERSION:-latest}
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      minio1:
        condition: service_healthy
      minio2:
        condition: service_healthy
      minio3:
        condition: service_healthy
      minio4:
        condition: service_healthy
    environment:
      # Application settings
      - BUYER_ENV=production
      - BUYER_WEB_PORT=8080

      # PostgreSQL connection
      - BUYER_DB_HOST=postgres
      - BUYER_DB_PORT=5432
      - BUYER_DB_NAME=${POSTGRES_DB}
      - BUYER_DB_USER=${POSTGRES_USER}
      - BUYER_DB_PASSWORD=${POSTGRES_PASSWORD}
      - BUYER_DB_SSLMODE=require

      # Authentication
      - BUYER_ENABLE_AUTH=true
      - BUYER_USERNAME=${BUYER_USERNAME}
      - BUYER_PASSWORD=${BUYER_PASSWORD}
      - BUYER_ENABLE_CSRF=true

      # MinIO settings
      - MINIO_ENDPOINT=minio1:9000
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD}
      - MINIO_USE_SSL=false
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 15s
    networks:
      - buyer-network
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "10"

  # NGINX Load Balancer
  nginx:
    image: nginx:alpine
    container_name: buyer-nginx-prod
    restart: unless-stopped
    depends_on:
      - buyer
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./certs:/etc/nginx/certs:ro
      - ./nginx/logs:/var/log/nginx
    networks:
      - buyer-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 3s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"

  # Prometheus (Monitoring)
  prometheus:
    image: prom/prometheus:latest
    container_name: buyer-prometheus-prod
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    networks:
      - buyer-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

volumes:
  postgres_data:
    driver: local
  minio1_data:
    driver: local
  minio2_data:
    driver: local
  minio3_data:
    driver: local
  minio4_data:
    driver: local
  prometheus_data:
    driver: local

networks:
  buyer-network:
    driver: bridge

# Usage:
#
# Prerequisites:
# 1. Create .env file with production credentials (see .env.example)
# 2. Generate TLS certificates:
#    mkdir -p certs
#    openssl req -new -x509 -days 365 -nodes \
#      -out certs/public.crt \
#      -keyout certs/private.key \
#      -subj "/C=US/ST=State/L=City/O=Organization/CN=buyer.yourdomain.com"
#
# 3. Create PostgreSQL config files:
#    mkdir -p postgres
#    # Add postgresql.conf and pg_hba.conf
#
# 4. Create NGINX config:
#    mkdir -p nginx
#    # Add nginx.conf with load balancing and SSL
#
# 5. Create Prometheus config:
#    mkdir -p prometheus
#    # Add prometheus.yml
#
# Deployment:
# 1. Deploy stack:
#    docker-compose -f docker-compose.prod.yml up -d
#
# 2. Scale buyer application:
#    docker-compose -f docker-compose.prod.yml up -d --scale buyer=5
#
# 3. View logs:
#    docker-compose -f docker-compose.prod.yml logs -f buyer
#
# 4. Check cluster status:
#    docker-compose -f docker-compose.prod.yml ps
#
# 5. Backup database:
#    docker-compose -f docker-compose.prod.yml exec postgres \
#      pg_dump -U buyer buyer > backup.sql
#
# 6. Update application (rolling update):
#    docker-compose -f docker-compose.prod.yml build buyer
#    docker-compose -f docker-compose.prod.yml up -d buyer
#
# 7. Stop services:
#    docker-compose -f docker-compose.prod.yml down
#
# Required Environment Variables (.env file):
#   POSTGRES_DB=buyer
#   POSTGRES_USER=buyer
#   POSTGRES_PASSWORD=<strong-password>
#   POSTGRES_REPLICATION_PASSWORD=<strong-password>
#   MINIO_ROOT_USER=<access-key>
#   MINIO_ROOT_PASSWORD=<secret-key-min-32-chars>
#   MINIO_REGION=us-east-1
#   BUYER_USERNAME=<admin-username>
#   BUYER_PASSWORD=<admin-password>
#   VERSION=1.0.0
